{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T15:21:45.240223Z",
     "start_time": "2024-06-17T15:21:39.339801Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n",
    "\n",
    "# 初始化Llama的tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "\n",
    "# 定义常量\n",
    "END_OF_TEXT_TOKEN = tokenizer.eos_token\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "        question = row['question']\n",
    "        response = row['response']\n",
    "\n",
    "        input_text = question + response\n",
    "        output_text = question + response + ' ' + END_OF_TEXT_TOKEN\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text)\n",
    "        output_ids = self.tokenizer.encode(output_text)[1:]  # 去掉第一个token\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'output_ids': output_ids,\n",
    "            'question_len': len(self.tokenizer.encode(question))\n",
    "        }\n",
    "\n",
    "# 定义自定义collate_fn\n",
    "def collate_fn(batch):\n",
    "    batch_input_ids = [item['input_ids'] for item in batch]\n",
    "    batch_output_ids = [item['output_ids'] for item in batch]\n",
    "    question_lengths = [item['question_len'] for item in batch]\n",
    "    \n",
    "    max_len = max(max(len(ids) for ids in batch_input_ids), max(len(ids) for ids in batch_output_ids))\n",
    "    \n",
    "    input_ids_padded = []\n",
    "    output_ids_padded = []\n",
    "    masks = []\n",
    "    \n",
    "    for input_ids, output_ids, q_len in zip(batch_input_ids, batch_output_ids, question_lengths):\n",
    "        input_len = len(input_ids)\n",
    "        output_len = len(output_ids)\n",
    "        \n",
    "        # Padding input_ids and output_ids to the same length\n",
    "        input_ids += [tokenizer.pad_token_id] * (max_len - input_len)\n",
    "        output_ids += [tokenizer.pad_token_id] * (max_len - output_len)\n",
    "        \n",
    "        # Create mask: 0 for question part, 1 for response part, 0 for padding and eos_token part\n",
    "        mask = [0] * q_len + [1] * (output_len - q_len) + [0] * (max_len - output_len)\n",
    "        \n",
    "        input_ids_padded.append(input_ids)\n",
    "        output_ids_padded.append(output_ids)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    input_ids_padded = torch.tensor(input_ids_padded, dtype=torch.long)\n",
    "    output_ids_padded = torch.tensor(output_ids_padded, dtype=torch.long)\n",
    "    masks = torch.tensor(masks, dtype=torch.long)\n",
    "    \n",
    "    return input_ids_padded, output_ids_padded, masks\n",
    "\n",
    "# 创建数据集和DataLoader\n",
    "custom_dataset = CustomDataset(dataset)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "# 示例：获取一个batch的数据\n",
    "for batch in dataloader:\n",
    "    input_ids, output_ids, masks = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Output IDs:\", output_ids)\n",
    "    print(\"Masks:\", masks)\n",
    "    break\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  2610,    686,    387,   2661,    264,   7271,    315,    264,   3383,\n",
      "           1156,     11,   1221,   1045,   1946,    315,    279,   3383,    624,\n",
      "           1986,   3383,    374,    911,   1667,    279,   5189,  11652,    323,\n",
      "          33437,    279,  11652,    311,  11765,   7662,  23752,    320,     49,\n",
      "           5262,      8,  23725,   2576,    315,    279,   1352,    320,  11501,\n",
      "             11,  24283,   1633,    568,    576,  68399,  23725,   2576,   7907,\n",
      "           1969,    387,   1741,    429,    279,  23725,   2576,  29257,  12322,\n",
      "            279,   5944,    323,  52694,    315,    279,   1946,  11652,     13,\n",
      "            576,   1946,    374,    264,  11652,    323,    279,   2550,    374,\n",
      "            264,   1140,    315,  23725,   2576,    315,    279,   1352,    508,\n",
      "          11501,     11,  24283,     11,   1633,     60,    429,  12322,    279,\n",
      "          11871,   3042,    304,    279,  11652,     13,   3197,    264,  11652,\n",
      "            702,    803,   1091,    220,     16,  68399,  98709,   3204,     11,\n",
      "            279,   2550,   1969,   6644,    678,    315,   1105,    382,     32,\n",
      "           6754,  41162,    320,    309,  35206,  21636,     82,   4910,    374,\n",
      "          18207,  28736,   1581,   2014,   1225,    316,    267,   1380,  41162,\n",
      "          29060,  15815,   1083,   1486,    624,   5097,  64772,    220,   4383,\n",
      "             32,   6754,  41162,    320,    309,  35206,  11583,    330,   4648,\n",
      "           4910,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   8097,    220,   4383,  40077,  29060,  15815,    497,    330,\n",
      "          27797,    518,    497,    330,  58737,  28736,   1581,   2014,   1225,\n",
      "            316,    267,   7026,     60, 151643],\n",
      "        [ 31115,    458,  13187,  36655,  37328,  11652,    429,  16555,    678,\n",
      "            419,    821,     25,  13699,  62566,   4678,   8180,    929,  10729,\n",
      "             26,  13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,\n",
      "           4678,   3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,\n",
      "          10728,    220,     18,    700,    315,    220,     20,     26,  13699,\n",
      "          62566,   4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,\n",
      "            374,    264,  69251,  32605,   8453,  10729,    448,    264,    220,\n",
      "             18,     14,     20,   6002,  10728,     11,   7407,   3143,   2009,\n",
      "           4716,   3776,     13, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Output IDs: tensor([[   686,    387,   2661,    264,   7271,    315,    264,   3383,   1156,\n",
      "             11,   1221,   1045,   1946,    315,    279,   3383,    624,   1986,\n",
      "           3383,    374,    911,   1667,    279,   5189,  11652,    323,  33437,\n",
      "            279,  11652,    311,  11765,   7662,  23752,    320,     49,   5262,\n",
      "              8,  23725,   2576,    315,    279,   1352,    320,  11501,     11,\n",
      "          24283,   1633,    568,    576,  68399,  23725,   2576,   7907,   1969,\n",
      "            387,   1741,    429,    279,  23725,   2576,  29257,  12322,    279,\n",
      "           5944,    323,  52694,    315,    279,   1946,  11652,     13,    576,\n",
      "           1946,    374,    264,  11652,    323,    279,   2550,    374,    264,\n",
      "           1140,    315,  23725,   2576,    315,    279,   1352,    508,  11501,\n",
      "             11,  24283,     11,   1633,     60,    429,  12322,    279,  11871,\n",
      "           3042,    304,    279,  11652,     13,   3197,    264,  11652,    702,\n",
      "            803,   1091,    220,     16,  68399,  98709,   3204,     11,    279,\n",
      "           2550,   1969,   6644,    678,    315,   1105,    382,     32,   6754,\n",
      "          41162,    320,    309,  35206,  21636,     82,   4910,    374,  18207,\n",
      "          28736,   1581,   2014,   1225,    316,    267,   1380,  41162,  29060,\n",
      "          15815,   1083,   1486,    624,   5097,  64772,    220,   4383,     32,\n",
      "           6754,  41162,    320,    309,  35206,  11583,    330,   4648,   4910,\n",
      "            497,    330,  58737,  28736,   1581,   2014,   1225,    316,    267,\n",
      "           8097,    220,   4383,  40077,  29060,  15815,    497,    330,  27797,\n",
      "            518,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   7026,     60,    220, 151645],\n",
      "        [   458,  13187,  36655,  37328,  11652,    429,  16555,    678,    419,\n",
      "            821,     25,  13699,  62566,   4678,   8180,    929,  10729,     26,\n",
      "          13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,   4678,\n",
      "           3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,  10728,\n",
      "            220,     18,    700,    315,    220,     20,     26,  13699,  62566,\n",
      "           4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,    374,\n",
      "            264,  69251,  32605,   8453,  10729,    448,    264,    220,     18,\n",
      "             14,     20,   6002,  10728,     11,   7407,   3143,   2009,   4716,\n",
      "           3776,     13,    220, 151645, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Masks: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:03:28.553058Z",
     "start_time": "2024-06-17T15:03:28.517221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例：获取一个batch的数据\n",
    "for batch in dataloader:\n",
    "    input_ids, output_ids, masks = batch\n",
    "    print(\"Input IDs:\", input_ids.shape)\n",
    "    print(\"Output IDs:\", output_ids.shape)\n",
    "    print(\"Masks:\", masks.shape)\n",
    "    break"
   ],
   "id": "293fc5a6fc319b32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([32, 919])\n",
      "Output IDs: torch.Size([32, 576])\n",
      "Masks: torch.Size([32, 919])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:32:30.397289Z",
     "start_time": "2024-06-17T15:32:24.705477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "        question = row['question']\n",
    "        response = row['response']\n",
    "\n",
    "        input_text = question + response\n",
    "        output_text = question + response + ' ' + self.tokenizer.eos_token\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text)\n",
    "        output_ids = self.tokenizer.encode(output_text)[1:]  # 去掉第一个token\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'output_ids': output_ids,\n",
    "            'question_len': len(self.tokenizer.encode(question))\n",
    "        }\n",
    "\n",
    "\n",
    "# 定义自定义collate_fn\n",
    "def collate_fn(batch, tokenizer):\n",
    "    batch_input_ids = [item['input_ids'] for item in batch]\n",
    "    batch_output_ids = [item['output_ids'] for item in batch]\n",
    "    question_lengths = [item['question_len'] for item in batch]\n",
    "\n",
    "    max_len = max(max(len(ids) for ids in batch_input_ids), max(len(ids) for ids in batch_output_ids))\n",
    "\n",
    "    input_ids_padded = []\n",
    "    output_ids_padded = []\n",
    "    masks = []\n",
    "\n",
    "    for input_ids, output_ids, q_len in zip(batch_input_ids, batch_output_ids, question_lengths):\n",
    "        input_len = len(input_ids)\n",
    "        output_len = len(output_ids)\n",
    "\n",
    "        # Padding input_ids and output_ids to the same length\n",
    "        input_ids += [tokenizer.pad_token_id] * (max_len - input_len)\n",
    "        output_ids += [tokenizer.pad_token_id] * (max_len - output_len)\n",
    "\n",
    "        # Create mask: 0 for question part, 1 for response part, 0 for padding and eos_token part\n",
    "        mask = [0] * q_len + [1] * (output_len - q_len) + [0] * (max_len - output_len)\n",
    "\n",
    "        input_ids_padded.append(input_ids)\n",
    "        output_ids_padded.append(output_ids)\n",
    "        masks.append(mask)\n",
    "\n",
    "    input_ids_padded = torch.tensor(input_ids_padded, dtype=torch.long)\n",
    "    output_ids_padded = torch.tensor(output_ids_padded, dtype=torch.long)\n",
    "    masks = torch.tensor(masks, dtype=torch.long)\n",
    "\n",
    "    return input_ids_padded, output_ids_padded, masks\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n",
    "\n",
    "# 初始化Llama的tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "\n",
    "# 定义常量\n",
    "END_OF_TEXT_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# 创建数据集和DataLoader\n",
    "custom_dataset = CustomDataset(dataset, tokenizer)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=2, collate_fn=lambda x: collate_fn(x, tokenizer))\n",
    "\n",
    "# 示例：获取一个batch的数据\n",
    "for batch in dataloader:\n",
    "    input_ids, output_ids, masks = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Output IDs:\", output_ids)\n",
    "    print(\"Masks:\", masks)\n",
    "    break"
   ],
   "id": "b86db9481d8f496d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  2610,    686,    387,   2661,    264,   7271,    315,    264,   3383,\n",
      "           1156,     11,   1221,   1045,   1946,    315,    279,   3383,    624,\n",
      "           1986,   3383,    374,    911,   1667,    279,   5189,  11652,    323,\n",
      "          33437,    279,  11652,    311,  11765,   7662,  23752,    320,     49,\n",
      "           5262,      8,  23725,   2576,    315,    279,   1352,    320,  11501,\n",
      "             11,  24283,   1633,    568,    576,  68399,  23725,   2576,   7907,\n",
      "           1969,    387,   1741,    429,    279,  23725,   2576,  29257,  12322,\n",
      "            279,   5944,    323,  52694,    315,    279,   1946,  11652,     13,\n",
      "            576,   1946,    374,    264,  11652,    323,    279,   2550,    374,\n",
      "            264,   1140,    315,  23725,   2576,    315,    279,   1352,    508,\n",
      "          11501,     11,  24283,     11,   1633,     60,    429,  12322,    279,\n",
      "          11871,   3042,    304,    279,  11652,     13,   3197,    264,  11652,\n",
      "            702,    803,   1091,    220,     16,  68399,  98709,   3204,     11,\n",
      "            279,   2550,   1969,   6644,    678,    315,   1105,    382,     32,\n",
      "           6754,  41162,    320,    309,  35206,  21636,     82,   4910,    374,\n",
      "          18207,  28736,   1581,   2014,   1225,    316,    267,   1380,  41162,\n",
      "          29060,  15815,   1083,   1486,    624,   5097,  64772,    220,   4383,\n",
      "             32,   6754,  41162,    320,    309,  35206,  11583,    330,   4648,\n",
      "           4910,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   8097,    220,   4383,  40077,  29060,  15815,    497,    330,\n",
      "          27797,    518,    497,    330,  58737,  28736,   1581,   2014,   1225,\n",
      "            316,    267,   7026,     60, 151643],\n",
      "        [ 31115,    458,  13187,  36655,  37328,  11652,    429,  16555,    678,\n",
      "            419,    821,     25,  13699,  62566,   4678,   8180,    929,  10729,\n",
      "             26,  13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,\n",
      "           4678,   3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,\n",
      "          10728,    220,     18,    700,    315,    220,     20,     26,  13699,\n",
      "          62566,   4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,\n",
      "            374,    264,  69251,  32605,   8453,  10729,    448,    264,    220,\n",
      "             18,     14,     20,   6002,  10728,     11,   7407,   3143,   2009,\n",
      "           4716,   3776,     13, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Output IDs: tensor([[   686,    387,   2661,    264,   7271,    315,    264,   3383,   1156,\n",
      "             11,   1221,   1045,   1946,    315,    279,   3383,    624,   1986,\n",
      "           3383,    374,    911,   1667,    279,   5189,  11652,    323,  33437,\n",
      "            279,  11652,    311,  11765,   7662,  23752,    320,     49,   5262,\n",
      "              8,  23725,   2576,    315,    279,   1352,    320,  11501,     11,\n",
      "          24283,   1633,    568,    576,  68399,  23725,   2576,   7907,   1969,\n",
      "            387,   1741,    429,    279,  23725,   2576,  29257,  12322,    279,\n",
      "           5944,    323,  52694,    315,    279,   1946,  11652,     13,    576,\n",
      "           1946,    374,    264,  11652,    323,    279,   2550,    374,    264,\n",
      "           1140,    315,  23725,   2576,    315,    279,   1352,    508,  11501,\n",
      "             11,  24283,     11,   1633,     60,    429,  12322,    279,  11871,\n",
      "           3042,    304,    279,  11652,     13,   3197,    264,  11652,    702,\n",
      "            803,   1091,    220,     16,  68399,  98709,   3204,     11,    279,\n",
      "           2550,   1969,   6644,    678,    315,   1105,    382,     32,   6754,\n",
      "          41162,    320,    309,  35206,  21636,     82,   4910,    374,  18207,\n",
      "          28736,   1581,   2014,   1225,    316,    267,   1380,  41162,  29060,\n",
      "          15815,   1083,   1486,    624,   5097,  64772,    220,   4383,     32,\n",
      "           6754,  41162,    320,    309,  35206,  11583,    330,   4648,   4910,\n",
      "            497,    330,  58737,  28736,   1581,   2014,   1225,    316,    267,\n",
      "           8097,    220,   4383,  40077,  29060,  15815,    497,    330,  27797,\n",
      "            518,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   7026,     60,    220, 151645],\n",
      "        [   458,  13187,  36655,  37328,  11652,    429,  16555,    678,    419,\n",
      "            821,     25,  13699,  62566,   4678,   8180,    929,  10729,     26,\n",
      "          13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,   4678,\n",
      "           3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,  10728,\n",
      "            220,     18,    700,    315,    220,     20,     26,  13699,  62566,\n",
      "           4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,    374,\n",
      "            264,  69251,  32605,   8453,  10729,    448,    264,    220,     18,\n",
      "             14,     20,   6002,  10728,     11,   7407,   3143,   2009,   4716,\n",
      "           3776,     13,    220, 151645, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Masks: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:40:15.705254Z",
     "start_time": "2024-06-17T15:40:15.698630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get batch without for\n",
    "batch = next(iter(dataloader))\n",
    "input_ids, output_ids, masks = batch\n",
    "print(\"Input IDs:\", input_ids.shape)\n",
    "print(\"Output IDs:\", output_ids.shape)\n",
    "print(\"Masks:\", masks.shape)"
   ],
   "id": "8a5d6851d2d3d4c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([2, 194])\n",
      "Output IDs: torch.Size([2, 194])\n",
      "Masks: torch.Size([2, 194])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:43:30.399501Z",
     "start_time": "2024-06-17T15:43:30.391205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader_iter = iter(dataloader)\n",
    "input_ids, output_ids, masks = next(dataloader_iter)\n",
    "print(\"Input IDs:\", input_ids.shape)\n",
    "print(\"Output IDs:\", output_ids.shape)\n",
    "print(\"Masks:\", masks.shape)"
   ],
   "id": "e6808a98a7e31bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([2, 194])\n",
      "Output IDs: torch.Size([2, 194])\n",
      "Masks: torch.Size([2, 194])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:43:39.668834Z",
     "start_time": "2024-06-17T15:43:39.658871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids, output_ids, masks = next(dataloader_iter)\n",
    "print(\"Input IDs:\", input_ids.shape)\n",
    "print(\"Output IDs:\", output_ids.shape)\n",
    "print(\"Masks:\", masks.shape)"
   ],
   "id": "f14fcd7f89606c98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([2, 458])\n",
      "Output IDs: torch.Size([2, 458])\n",
      "Masks: torch.Size([2, 458])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:44:53.480896Z",
     "start_time": "2024-06-19T09:44:48.086975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n"
   ],
   "id": "54fc7e43b5830395",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:44:54.151632Z",
     "start_time": "2024-06-19T09:44:53.482403Z"
    }
   },
   "cell_type": "code",
   "source": "dataset['train']",
   "id": "e00251b1b73f8d8c",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column train not in the dataset. Current columns in the dataset: ['id', 'system_prompt', 'question', 'response']\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\datasets\\arrow_dataset.py:2861\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2859\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[0;32m   2860\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2861\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem(key)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\datasets\\arrow_dataset.py:2845\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2843\u001B[0m format_kwargs \u001B[38;5;241m=\u001B[39m format_kwargs \u001B[38;5;28;01mif\u001B[39;00m format_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[0;32m   2844\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[1;32m-> 2845\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[0;32m   2846\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m format_table(\n\u001B[0;32m   2847\u001B[0m     pa_subtable, key, formatter\u001B[38;5;241m=\u001B[39mformatter, format_columns\u001B[38;5;241m=\u001B[39mformat_columns, output_all_columns\u001B[38;5;241m=\u001B[39moutput_all_columns\n\u001B[0;32m   2848\u001B[0m )\n\u001B[0;32m   2849\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\datasets\\formatting\\formatting.py:584\u001B[0m, in \u001B[0;36mquery_table\u001B[1;34m(table, key, indices)\u001B[0m\n\u001B[0;32m    582\u001B[0m         _raise_bad_key_type(key)\n\u001B[0;32m    583\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m--> 584\u001B[0m     _check_valid_column_key(key, table\u001B[38;5;241m.\u001B[39mcolumn_names)\n\u001B[0;32m    585\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    586\u001B[0m     size \u001B[38;5;241m=\u001B[39m indices\u001B[38;5;241m.\u001B[39mnum_rows \u001B[38;5;28;01mif\u001B[39;00m indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m table\u001B[38;5;241m.\u001B[39mnum_rows\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\datasets\\formatting\\formatting.py:521\u001B[0m, in \u001B[0;36m_check_valid_column_key\u001B[1;34m(key, columns)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_valid_column_key\u001B[39m(key: \u001B[38;5;28mstr\u001B[39m, columns: List[\u001B[38;5;28mstr\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m columns:\n\u001B[1;32m--> 521\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in the dataset. Current columns in the dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumns\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Column train not in the dataset. Current columns in the dataset: ['id', 'system_prompt', 'question', 'response']\""
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:41:06.560619Z",
     "start_time": "2024-06-19T09:41:05.788906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = dataset.train_test_split(test_size=0.1)\n",
    "ds"
   ],
   "id": "c5968f10349d663b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'system_prompt', 'question', 'response'],\n",
       "        num_rows: 3810530\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'system_prompt', 'question', 'response'],\n",
       "        num_rows: 423393\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:41:23.425853Z",
     "start_time": "2024-06-19T09:41:23.418585Z"
    }
   },
   "cell_type": "code",
   "source": "ds['train']",
   "id": "b530b91a3ca03328",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'system_prompt', 'question', 'response'],\n",
       "    num_rows: 3810530\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 初始化Llama的tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "# 创建数据集和DataLoader\n",
    "custom_dataset = CustomDataset(dataset, tokenizer)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=64, collate_fn=lambda x: collate_fn(x, tokenizer))\n",
    "\n",
    "dataiter = iter(dataloader)"
   ],
   "id": "ee2159d1f45208a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
