{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T15:21:45.240223Z",
     "start_time": "2024-06-17T15:21:39.339801Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n",
    "\n",
    "# 初始化Llama的tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "\n",
    "# 定义常量\n",
    "END_OF_TEXT_TOKEN = tokenizer.eos_token\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "        question = row['question']\n",
    "        response = row['response']\n",
    "\n",
    "        input_text = question + response\n",
    "        output_text = question + response + ' ' + END_OF_TEXT_TOKEN\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text)\n",
    "        output_ids = self.tokenizer.encode(output_text)[1:]  # 去掉第一个token\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'output_ids': output_ids,\n",
    "            'question_len': len(self.tokenizer.encode(question))\n",
    "        }\n",
    "\n",
    "# 定义自定义collate_fn\n",
    "def collate_fn(batch):\n",
    "    batch_input_ids = [item['input_ids'] for item in batch]\n",
    "    batch_output_ids = [item['output_ids'] for item in batch]\n",
    "    question_lengths = [item['question_len'] for item in batch]\n",
    "    \n",
    "    max_len = max(max(len(ids) for ids in batch_input_ids), max(len(ids) for ids in batch_output_ids))\n",
    "    \n",
    "    input_ids_padded = []\n",
    "    output_ids_padded = []\n",
    "    masks = []\n",
    "    \n",
    "    for input_ids, output_ids, q_len in zip(batch_input_ids, batch_output_ids, question_lengths):\n",
    "        input_len = len(input_ids)\n",
    "        output_len = len(output_ids)\n",
    "        \n",
    "        # Padding input_ids and output_ids to the same length\n",
    "        input_ids += [tokenizer.pad_token_id] * (max_len - input_len)\n",
    "        output_ids += [tokenizer.pad_token_id] * (max_len - output_len)\n",
    "        \n",
    "        # Create mask: 0 for question part, 1 for response part, 0 for padding and eos_token part\n",
    "        mask = [0] * q_len + [1] * (output_len - q_len) + [0] * (max_len - output_len)\n",
    "        \n",
    "        input_ids_padded.append(input_ids)\n",
    "        output_ids_padded.append(output_ids)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    input_ids_padded = torch.tensor(input_ids_padded, dtype=torch.long)\n",
    "    output_ids_padded = torch.tensor(output_ids_padded, dtype=torch.long)\n",
    "    masks = torch.tensor(masks, dtype=torch.long)\n",
    "    \n",
    "    return input_ids_padded, output_ids_padded, masks\n",
    "\n",
    "# 创建数据集和DataLoader\n",
    "custom_dataset = CustomDataset(dataset)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "# 示例：获取一个batch的数据\n",
    "for batch in dataloader:\n",
    "    input_ids, output_ids, masks = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Output IDs:\", output_ids)\n",
    "    print(\"Masks:\", masks)\n",
    "    break\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  2610,    686,    387,   2661,    264,   7271,    315,    264,   3383,\n",
      "           1156,     11,   1221,   1045,   1946,    315,    279,   3383,    624,\n",
      "           1986,   3383,    374,    911,   1667,    279,   5189,  11652,    323,\n",
      "          33437,    279,  11652,    311,  11765,   7662,  23752,    320,     49,\n",
      "           5262,      8,  23725,   2576,    315,    279,   1352,    320,  11501,\n",
      "             11,  24283,   1633,    568,    576,  68399,  23725,   2576,   7907,\n",
      "           1969,    387,   1741,    429,    279,  23725,   2576,  29257,  12322,\n",
      "            279,   5944,    323,  52694,    315,    279,   1946,  11652,     13,\n",
      "            576,   1946,    374,    264,  11652,    323,    279,   2550,    374,\n",
      "            264,   1140,    315,  23725,   2576,    315,    279,   1352,    508,\n",
      "          11501,     11,  24283,     11,   1633,     60,    429,  12322,    279,\n",
      "          11871,   3042,    304,    279,  11652,     13,   3197,    264,  11652,\n",
      "            702,    803,   1091,    220,     16,  68399,  98709,   3204,     11,\n",
      "            279,   2550,   1969,   6644,    678,    315,   1105,    382,     32,\n",
      "           6754,  41162,    320,    309,  35206,  21636,     82,   4910,    374,\n",
      "          18207,  28736,   1581,   2014,   1225,    316,    267,   1380,  41162,\n",
      "          29060,  15815,   1083,   1486,    624,   5097,  64772,    220,   4383,\n",
      "             32,   6754,  41162,    320,    309,  35206,  11583,    330,   4648,\n",
      "           4910,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   8097,    220,   4383,  40077,  29060,  15815,    497,    330,\n",
      "          27797,    518,    497,    330,  58737,  28736,   1581,   2014,   1225,\n",
      "            316,    267,   7026,     60, 151643],\n",
      "        [ 31115,    458,  13187,  36655,  37328,  11652,    429,  16555,    678,\n",
      "            419,    821,     25,  13699,  62566,   4678,   8180,    929,  10729,\n",
      "             26,  13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,\n",
      "           4678,   3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,\n",
      "          10728,    220,     18,    700,    315,    220,     20,     26,  13699,\n",
      "          62566,   4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,\n",
      "            374,    264,  69251,  32605,   8453,  10729,    448,    264,    220,\n",
      "             18,     14,     20,   6002,  10728,     11,   7407,   3143,   2009,\n",
      "           4716,   3776,     13, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Output IDs: tensor([[   686,    387,   2661,    264,   7271,    315,    264,   3383,   1156,\n",
      "             11,   1221,   1045,   1946,    315,    279,   3383,    624,   1986,\n",
      "           3383,    374,    911,   1667,    279,   5189,  11652,    323,  33437,\n",
      "            279,  11652,    311,  11765,   7662,  23752,    320,     49,   5262,\n",
      "              8,  23725,   2576,    315,    279,   1352,    320,  11501,     11,\n",
      "          24283,   1633,    568,    576,  68399,  23725,   2576,   7907,   1969,\n",
      "            387,   1741,    429,    279,  23725,   2576,  29257,  12322,    279,\n",
      "           5944,    323,  52694,    315,    279,   1946,  11652,     13,    576,\n",
      "           1946,    374,    264,  11652,    323,    279,   2550,    374,    264,\n",
      "           1140,    315,  23725,   2576,    315,    279,   1352,    508,  11501,\n",
      "             11,  24283,     11,   1633,     60,    429,  12322,    279,  11871,\n",
      "           3042,    304,    279,  11652,     13,   3197,    264,  11652,    702,\n",
      "            803,   1091,    220,     16,  68399,  98709,   3204,     11,    279,\n",
      "           2550,   1969,   6644,    678,    315,   1105,    382,     32,   6754,\n",
      "          41162,    320,    309,  35206,  21636,     82,   4910,    374,  18207,\n",
      "          28736,   1581,   2014,   1225,    316,    267,   1380,  41162,  29060,\n",
      "          15815,   1083,   1486,    624,   5097,  64772,    220,   4383,     32,\n",
      "           6754,  41162,    320,    309,  35206,  11583,    330,   4648,   4910,\n",
      "            497,    330,  58737,  28736,   1581,   2014,   1225,    316,    267,\n",
      "           8097,    220,   4383,  40077,  29060,  15815,    497,    330,  27797,\n",
      "            518,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   7026,     60,    220, 151645],\n",
      "        [   458,  13187,  36655,  37328,  11652,    429,  16555,    678,    419,\n",
      "            821,     25,  13699,  62566,   4678,   8180,    929,  10729,     26,\n",
      "          13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,   4678,\n",
      "           3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,  10728,\n",
      "            220,     18,    700,    315,    220,     20,     26,  13699,  62566,\n",
      "           4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,    374,\n",
      "            264,  69251,  32605,   8453,  10729,    448,    264,    220,     18,\n",
      "             14,     20,   6002,  10728,     11,   7407,   3143,   2009,   4716,\n",
      "           3776,     13,    220, 151645, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Masks: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:03:28.553058Z",
     "start_time": "2024-06-17T15:03:28.517221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例：获取一个batch的数据\n",
    "for batch in dataloader:\n",
    "    input_ids, output_ids, masks = batch\n",
    "    print(\"Input IDs:\", input_ids.shape)\n",
    "    print(\"Output IDs:\", output_ids.shape)\n",
    "    print(\"Masks:\", masks.shape)\n",
    "    break"
   ],
   "id": "293fc5a6fc319b32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([32, 919])\n",
      "Output IDs: torch.Size([32, 576])\n",
      "Masks: torch.Size([32, 919])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:32:30.397289Z",
     "start_time": "2024-06-17T15:32:24.705477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "        question = row['question']\n",
    "        response = row['response']\n",
    "\n",
    "        input_text = question + response\n",
    "        output_text = question + response + ' ' + self.tokenizer.eos_token\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text)\n",
    "        output_ids = self.tokenizer.encode(output_text)[1:]  # 去掉第一个token\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'output_ids': output_ids,\n",
    "            'question_len': len(self.tokenizer.encode(question))\n",
    "        }\n",
    "\n",
    "\n",
    "# 定义自定义collate_fn\n",
    "def collate_fn(batch, tokenizer):\n",
    "    batch_input_ids = [item['input_ids'] for item in batch]\n",
    "    batch_output_ids = [item['output_ids'] for item in batch]\n",
    "    question_lengths = [item['question_len'] for item in batch]\n",
    "\n",
    "    max_len = max(max(len(ids) for ids in batch_input_ids), max(len(ids) for ids in batch_output_ids))\n",
    "\n",
    "    input_ids_padded = []\n",
    "    output_ids_padded = []\n",
    "    masks = []\n",
    "\n",
    "    for input_ids, output_ids, q_len in zip(batch_input_ids, batch_output_ids, question_lengths):\n",
    "        input_len = len(input_ids)\n",
    "        output_len = len(output_ids)\n",
    "\n",
    "        # Padding input_ids and output_ids to the same length\n",
    "        input_ids += [tokenizer.pad_token_id] * (max_len - input_len)\n",
    "        output_ids += [tokenizer.pad_token_id] * (max_len - output_len)\n",
    "\n",
    "        # Create mask: 0 for question part, 1 for response part, 0 for padding and eos_token part\n",
    "        mask = [0] * q_len + [1] * (output_len - q_len) + [0] * (max_len - output_len)\n",
    "\n",
    "        input_ids_padded.append(input_ids)\n",
    "        output_ids_padded.append(output_ids)\n",
    "        masks.append(mask)\n",
    "\n",
    "    input_ids_padded = torch.tensor(input_ids_padded, dtype=torch.long)\n",
    "    output_ids_padded = torch.tensor(output_ids_padded, dtype=torch.long)\n",
    "    masks = torch.tensor(masks, dtype=torch.long)\n",
    "\n",
    "    return input_ids_padded, output_ids_padded, masks\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n",
    "\n",
    "# 初始化Llama的tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "\n",
    "# 定义常量\n",
    "END_OF_TEXT_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# 创建数据集和DataLoader\n",
    "custom_dataset = CustomDataset(dataset, tokenizer)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=2, collate_fn=lambda x: collate_fn(x, tokenizer))\n",
    "\n",
    "# 示例：获取一个batch的数据\n",
    "for batch in dataloader:\n",
    "    input_ids, output_ids, masks = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Output IDs:\", output_ids)\n",
    "    print(\"Masks:\", masks)\n",
    "    break"
   ],
   "id": "b86db9481d8f496d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  2610,    686,    387,   2661,    264,   7271,    315,    264,   3383,\n",
      "           1156,     11,   1221,   1045,   1946,    315,    279,   3383,    624,\n",
      "           1986,   3383,    374,    911,   1667,    279,   5189,  11652,    323,\n",
      "          33437,    279,  11652,    311,  11765,   7662,  23752,    320,     49,\n",
      "           5262,      8,  23725,   2576,    315,    279,   1352,    320,  11501,\n",
      "             11,  24283,   1633,    568,    576,  68399,  23725,   2576,   7907,\n",
      "           1969,    387,   1741,    429,    279,  23725,   2576,  29257,  12322,\n",
      "            279,   5944,    323,  52694,    315,    279,   1946,  11652,     13,\n",
      "            576,   1946,    374,    264,  11652,    323,    279,   2550,    374,\n",
      "            264,   1140,    315,  23725,   2576,    315,    279,   1352,    508,\n",
      "          11501,     11,  24283,     11,   1633,     60,    429,  12322,    279,\n",
      "          11871,   3042,    304,    279,  11652,     13,   3197,    264,  11652,\n",
      "            702,    803,   1091,    220,     16,  68399,  98709,   3204,     11,\n",
      "            279,   2550,   1969,   6644,    678,    315,   1105,    382,     32,\n",
      "           6754,  41162,    320,    309,  35206,  21636,     82,   4910,    374,\n",
      "          18207,  28736,   1581,   2014,   1225,    316,    267,   1380,  41162,\n",
      "          29060,  15815,   1083,   1486,    624,   5097,  64772,    220,   4383,\n",
      "             32,   6754,  41162,    320,    309,  35206,  11583,    330,   4648,\n",
      "           4910,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   8097,    220,   4383,  40077,  29060,  15815,    497,    330,\n",
      "          27797,    518,    497,    330,  58737,  28736,   1581,   2014,   1225,\n",
      "            316,    267,   7026,     60, 151643],\n",
      "        [ 31115,    458,  13187,  36655,  37328,  11652,    429,  16555,    678,\n",
      "            419,    821,     25,  13699,  62566,   4678,   8180,    929,  10729,\n",
      "             26,  13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,\n",
      "           4678,   3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,\n",
      "          10728,    220,     18,    700,    315,    220,     20,     26,  13699,\n",
      "          62566,   4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,\n",
      "            374,    264,  69251,  32605,   8453,  10729,    448,    264,    220,\n",
      "             18,     14,     20,   6002,  10728,     11,   7407,   3143,   2009,\n",
      "           4716,   3776,     13, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Output IDs: tensor([[   686,    387,   2661,    264,   7271,    315,    264,   3383,   1156,\n",
      "             11,   1221,   1045,   1946,    315,    279,   3383,    624,   1986,\n",
      "           3383,    374,    911,   1667,    279,   5189,  11652,    323,  33437,\n",
      "            279,  11652,    311,  11765,   7662,  23752,    320,     49,   5262,\n",
      "              8,  23725,   2576,    315,    279,   1352,    320,  11501,     11,\n",
      "          24283,   1633,    568,    576,  68399,  23725,   2576,   7907,   1969,\n",
      "            387,   1741,    429,    279,  23725,   2576,  29257,  12322,    279,\n",
      "           5944,    323,  52694,    315,    279,   1946,  11652,     13,    576,\n",
      "           1946,    374,    264,  11652,    323,    279,   2550,    374,    264,\n",
      "           1140,    315,  23725,   2576,    315,    279,   1352,    508,  11501,\n",
      "             11,  24283,     11,   1633,     60,    429,  12322,    279,  11871,\n",
      "           3042,    304,    279,  11652,     13,   3197,    264,  11652,    702,\n",
      "            803,   1091,    220,     16,  68399,  98709,   3204,     11,    279,\n",
      "           2550,   1969,   6644,    678,    315,   1105,    382,     32,   6754,\n",
      "          41162,    320,    309,  35206,  21636,     82,   4910,    374,  18207,\n",
      "          28736,   1581,   2014,   1225,    316,    267,   1380,  41162,  29060,\n",
      "          15815,   1083,   1486,    624,   5097,  64772,    220,   4383,     32,\n",
      "           6754,  41162,    320,    309,  35206,  11583,    330,   4648,   4910,\n",
      "            497,    330,  58737,  28736,   1581,   2014,   1225,    316,    267,\n",
      "           8097,    220,   4383,  40077,  29060,  15815,    497,    330,  27797,\n",
      "            518,    497,    330,  58737,  28736,   1581,   2014,   1225,    316,\n",
      "            267,   7026,     60,    220, 151645],\n",
      "        [   458,  13187,  36655,  37328,  11652,    429,  16555,    678,    419,\n",
      "            821,     25,  13699,  62566,   4678,   8180,    929,  10729,     26,\n",
      "          13699,  62566,   4678,   3607,   8453,     26,  13699,  62566,   4678,\n",
      "           3349,   6046,  23193,     26,  13699,  62566,   4678,   6002,  10728,\n",
      "            220,     18,    700,    315,    220,     20,     26,  13699,  62566,\n",
      "           4678,   3143,   2009,   4716,   3776,  33648,  62566,   4678,    374,\n",
      "            264,  69251,  32605,   8453,  10729,    448,    264,    220,     18,\n",
      "             14,     20,   6002,  10728,     11,   7407,   3143,   2009,   4716,\n",
      "           3776,     13,    220, 151645, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "Masks: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:40:15.705254Z",
     "start_time": "2024-06-17T15:40:15.698630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get batch without for\n",
    "batch = next(iter(dataloader))\n",
    "input_ids, output_ids, masks = batch\n",
    "print(\"Input IDs:\", input_ids.shape)\n",
    "print(\"Output IDs:\", output_ids.shape)\n",
    "print(\"Masks:\", masks.shape)"
   ],
   "id": "8a5d6851d2d3d4c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([2, 194])\n",
      "Output IDs: torch.Size([2, 194])\n",
      "Masks: torch.Size([2, 194])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:43:30.399501Z",
     "start_time": "2024-06-17T15:43:30.391205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader_iter = iter(dataloader)\n",
    "input_ids, output_ids, masks = next(dataloader_iter)\n",
    "print(\"Input IDs:\", input_ids.shape)\n",
    "print(\"Output IDs:\", output_ids.shape)\n",
    "print(\"Masks:\", masks.shape)"
   ],
   "id": "e6808a98a7e31bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([2, 194])\n",
      "Output IDs: torch.Size([2, 194])\n",
      "Masks: torch.Size([2, 194])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:43:39.668834Z",
     "start_time": "2024-06-17T15:43:39.658871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids, output_ids, masks = next(dataloader_iter)\n",
    "print(\"Input IDs:\", input_ids.shape)\n",
    "print(\"Output IDs:\", output_ids.shape)\n",
    "print(\"Masks:\", masks.shape)"
   ],
   "id": "f14fcd7f89606c98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([2, 458])\n",
      "Output IDs: torch.Size([2, 458])\n",
      "Masks: torch.Size([2, 458])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "54fc7e43b5830395"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
