{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "学术资源加速\n",
    "\n",
    "以下为可以加速访问的学术资源地址：\n",
    "- github.com\n",
    "- githubusercontent.com\n",
    "- githubassets.com\n",
    "- huggingface.co"
   ],
   "id": "78b88c1c3da764e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:38:11.420881Z",
     "start_time": "2024-06-09T16:38:11.414354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "        "
   ],
   "id": "50ad69a97931f2ec",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "加载自定义llama模型并进行推理，测试内部运行逻辑",
   "id": "f301109f48e3ab4"
  },
  {
   "cell_type": "code",
   "id": "e6f2835521c01f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T05:15:23.330496Z",
     "start_time": "2024-06-13T05:15:11.201563Z"
    }
   },
   "source": [
    "from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n",
    "import math\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast, BaseModelOutputWithPast\n",
    "from transformers.utils import add_start_docstrings_to_model_forward, replace_return_docstrings, logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import AutoTokenizer, Cache, AutoTokenizer, AutoModelForCausalLM, LlamaConfig, add_start_docstrings, DynamicCache, StaticCache, BitsAndBytesConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM, LLAMA_INPUTS_DOCSTRING, _CONFIG_FOR_DOC, LlamaAttention, apply_rotary_pos_emb, repeat_kv, LlamaMLP, \\\n",
    "    LlamaFlashAttention2, LlamaSdpaAttention, LlamaDecoderLayer, LLAMA_START_DOCSTRING, LlamaPreTrainedModel, LlamaRMSNorm, LlamaModel\n",
    "\n",
    "\n",
    "class TestLlamaAttention(LlamaAttention):\n",
    "    def __init__(self, config: LlamaConfig, layer_idx: Optional[int] = None):\n",
    "        super().__init__(config, layer_idx)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_value: Optional[Cache] = None,\n",
    "        output_attentions: bool = False,\n",
    "        use_cache: bool = False,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "        \n",
    "        print(\"cache_position\", cache_position)\n",
    "        print(\"position_ids\", position_ids)\n",
    "        \n",
    "        bsz, q_len, _ = hidden_states.size()\n",
    "\n",
    "        if self.config.pretraining_tp > 1:\n",
    "            key_value_slicing = (self.num_key_value_heads * self.head_dim) // self.config.pretraining_tp\n",
    "            query_slices = self.q_proj.weight.split(\n",
    "                (self.num_heads * self.head_dim) // self.config.pretraining_tp, dim=0\n",
    "            )\n",
    "            key_slices = self.k_proj.weight.split(key_value_slicing, dim=0)\n",
    "            value_slices = self.v_proj.weight.split(key_value_slicing, dim=0)\n",
    "\n",
    "            query_states = [F.linear(hidden_states, query_slices[i]) for i in range(self.config.pretraining_tp)]\n",
    "            query_states = torch.cat(query_states, dim=-1)\n",
    "\n",
    "            key_states = [F.linear(hidden_states, key_slices[i]) for i in range(self.config.pretraining_tp)]\n",
    "            key_states = torch.cat(key_states, dim=-1)\n",
    "\n",
    "            value_states = [F.linear(hidden_states, value_slices[i]) for i in range(self.config.pretraining_tp)]\n",
    "            value_states = torch.cat(value_states, dim=-1)\n",
    "\n",
    "        else:\n",
    "            query_states = self.q_proj(hidden_states)\n",
    "            key_states = self.k_proj(hidden_states)\n",
    "            value_states = self.v_proj(hidden_states)\n",
    "\n",
    "        query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "        value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "        # print(\"query_states1\", query_states.shape)\n",
    "        # print(\"key_states1\", key_states.shape)\n",
    "        # print(\"value_states1\", value_states.shape)\n",
    "\n",
    "        cos, sin = self.rotary_emb(value_states, position_ids)\n",
    "        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
    "\n",
    "        if past_key_value is not None:\n",
    "            # sin and cos are specific to RoPE models; cache_position needed for the static cache\n",
    "            cache_kwargs = {\"sin\": sin, \"cos\": cos, \"cache_position\": cache_position}\n",
    "            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)\n",
    "\n",
    "        key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "        value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "        # print(\"query_states2\", query_states.shape)\n",
    "        # print(\"key_states2\", key_states.shape)\n",
    "        # print(\"value_states2\", value_states.shape)\n",
    "\n",
    "        attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        if attention_mask is not None:  # no matter the length, we just slice it\n",
    "            # print(\"attention_mask\", attention_mask[0, 0, :])\n",
    "            causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]\n",
    "            # print(\"causal_mask\", causal_mask.shape)\n",
    "            attn_weights = attn_weights + causal_mask\n",
    "\n",
    "        # upcast attention to fp32\n",
    "        attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
    "        # print(\"attn_weights\", attn_weights)\n",
    "        attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_weights, value_states)\n",
    "\n",
    "        if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
    "            raise ValueError(\n",
    "                f\"`attn_output` should be of size {(bsz, self.num_heads, q_len, self.head_dim)}, but is\"\n",
    "                f\" {attn_output.size()}\"\n",
    "            )\n",
    "\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "\n",
    "        attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)\n",
    "\n",
    "        if self.config.pretraining_tp > 1:\n",
    "            attn_output = attn_output.split(self.hidden_size // self.config.pretraining_tp, dim=2)\n",
    "            o_proj_slices = self.o_proj.weight.split(self.hidden_size // self.config.pretraining_tp, dim=1)\n",
    "            attn_output = sum([F.linear(attn_output[i], o_proj_slices[i]) for i in range(self.config.pretraining_tp)])\n",
    "        else:\n",
    "            attn_output = self.o_proj(attn_output)\n",
    "\n",
    "        if not output_attentions:\n",
    "            attn_weights = None\n",
    "\n",
    "        return attn_output, attn_weights, past_key_value\n",
    "\n",
    "\n",
    "class TestLlamaDecoderLayer(LlamaDecoderLayer):\n",
    "    def __init__(self, config: LlamaConfig, layer_idx: int):\n",
    "        super().__init__(config, layer_idx)\n",
    "        \n",
    "        self.self_attn = TestLlamaAttention(config=config, layer_idx=layer_idx)\n",
    "\n",
    "\n",
    "class TestLlamaModel(LlamaModel):\n",
    "\n",
    "    def __init__(self, config: LlamaConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TestLlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]\n",
    "        )\n",
    "\n",
    "\n",
    "class TestLlamaForCausalLM(LlamaForCausalLM):\n",
    "    def __init__(self, config: LlamaConfig):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.model = TestLlamaModel(config)\n",
    "        \n",
    "    @torch.inference_mode()\n",
    "    def forward_inference(self, \n",
    "                          tokens: torch.Tensor,\n",
    "                          start_pos: int,\n",
    "                          max_context_window: int,\n",
    "                         ):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = self.mask[:seqlen, :seqlen]\n",
    "        # When performing key-value caching, we compute the attention scores\n",
    "        # only for the new sequence. Thus, the matrix of scores is of size\n",
    "        # (seqlen, cache_len + seqlen), and the only masked entries are (i, j) for\n",
    "        # j > cache_len + i, since row i corresponds to token cache_len + i.\n",
    "        mask = torch.hstack(\n",
    "            [torch.zeros((seqlen, start_pos), device=tokens.device), mask]\n",
    "        ).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(\n",
    "                h, \n",
    "                freqs_cis, \n",
    "                mask, \n",
    "                start_pos = start_pos\n",
    "            )\n",
    "        h = self.norm(h)\n",
    "        logits = self.output(h).float()\n",
    "        return logits\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "model_list = [\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    \"TinyLlama/TinyLlama_v1.1_chinese\",\n",
    "]\n",
    "\n",
    "model_id = model_list[0]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    token=\"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\",\n",
    ")\n",
    "\n",
    "# 添加填充标记\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Quantization, if needed\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "model = TestLlamaForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    token=\"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\",\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dec48bd0ac94be295a8492990cfac6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T04:57:59.188794Z",
     "start_time": "2024-06-13T04:57:59.068818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=4, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\"trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282\""
   ],
   "id": "9d2489afd42eeffa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,097,152 || all params: 6,740,512,768 || trainable%: 0.0311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "9981565ccf1c5757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T19:32:20.572932Z",
     "start_time": "2024-06-10T19:31:56.139599Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# 数据预处理\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=16)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 训练和验证数据集\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(2000))  # 选择一部分数据进行训练\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))    # 选择一部分数据进行验证\n",
    "\n",
    "# 配置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# 创建 Trainer 实例\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=None,  # 默认数据整理器\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型\n",
    "trainer.save_model(\"./trained_model\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e93763a39094266bc451dbea9af969d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fzkuj\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       device='cuda:0')\n",
      "attention_mask tensor([[ 0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3895e+38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (120) to match target batch_size (7).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 42\u001B[0m\n\u001B[0;32m     32\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     33\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     34\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     38\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,  \u001B[38;5;66;03m# 默认数据整理器\u001B[39;00m\n\u001B[0;32m     39\u001B[0m )\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# 保存模型\u001B[39;00m\n\u001B[0;32m     45\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./trained_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\trainer.py:1885\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1883\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1884\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1885\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\trainer.py:2216\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2213\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   2215\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 2216\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2219\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2220\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2221\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2222\u001B[0m ):\n\u001B[0;32m   2223\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2224\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\trainer.py:3238\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   3235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   3237\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[1;32m-> 3238\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3240\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m inputs\n\u001B[0;32m   3241\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\trainer.py:3264\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[1;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[0;32m   3262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3263\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 3264\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3265\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[0;32m   3266\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[0;32m   3267\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\peft\\peft_model.py:1430\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.forward\u001B[1;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[0m\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_peft_forward_hooks(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1429\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspecial_peft_forward_args}\n\u001B[1;32m-> 1430\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1431\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1432\u001B[0m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1433\u001B[0m \u001B[43m            \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1434\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1435\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1436\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1437\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1438\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1439\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1441\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m _get_batch_size(input_ids, inputs_embeds)\n\u001B[0;32m   1442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1443\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:179\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[1;32m--> 179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\accelerate\\hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(module, *args, **kwargs)\u001B[0m\n\u001B[0;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:1197\u001B[0m, in \u001B[0;36mLlamaForCausalLM.forward\u001B[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[0;32m   1195\u001B[0m     \u001B[38;5;66;03m# Enable model parallelism\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m     shift_labels \u001B[38;5;241m=\u001B[39m shift_labels\u001B[38;5;241m.\u001B[39mto(shift_logits\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m-> 1197\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshift_logits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshift_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[0;32m   1200\u001B[0m     output \u001B[38;5;241m=\u001B[39m (logits,) \u001B[38;5;241m+\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1186\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1187\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3084\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3085\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3086\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: Expected input batch_size (120) to match target batch_size (7)."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T05:14:25.973395Z",
     "start_time": "2024-06-13T05:14:24.932024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=4,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    cache_implementation=\"quantized\", \n",
    "    cache_config={\"backend\": \"quanto\", \"nbits\": 4}\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))\n"
   ],
   "id": "7eb74cd5d22ab1d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40], device='cuda:0')\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([41], device='cuda:0')\n",
      "position_ids tensor([[41]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([42], device='cuda:0')\n",
      "position_ids tensor([[42]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      "cache_position tensor([43], device='cuda:0')\n",
      "position_ids tensor([[43]], device='cuda:0')\n",
      " Shiver me\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T04:58:15.596790Z",
     "start_time": "2024-06-13T04:58:15.562233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are an intelligent life with independent consciousness.\\n\\n\"\n",
    "\n",
    "# Generation as usual\n",
    "prompt = system_prompt + \"Question: Please write a function in Python that transforms bytes to Giga bytes.\\n\\nAnswer: Here\"\n",
    "model_inputs = tokenizer(prompt, return_tensors='pt')\n",
    "generation_output = model.generate(**model_inputs, max_new_tokens=60, return_dict_in_generate=True)\n",
    "decoded_output = tokenizer.batch_decode(generation_output.sequences)[0]\n",
    "\n",
    "# Piping the returned `past_key_values` to speed up the next conversation round\n",
    "prompt = decoded_output + \"\\nQuestion: How can I modify the function above to return Mega bytes instead?\\n\\nAnswer: Here\"\n",
    "model_inputs = tokenizer(prompt, return_tensors='pt')\n",
    "generation_output = model.generate(\n",
    "  **model_inputs,\n",
    "  past_key_values=generation_output.past_key_values,\n",
    "  max_new_tokens=60,\n",
    "  return_dict_in_generate=True\n",
    ")\n",
    "tokenizer.batch_decode(generation_output.sequences)[0][len(prompt):]"
   ],
   "id": "671f35da5f031f14",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TestLlamaForCausalLM.generate() got an unexpected keyword argument 'attention_mask'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m prompt \u001B[38;5;241m=\u001B[39m system_prompt \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuestion: Please write a function in Python that transforms bytes to Giga bytes.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAnswer: Here\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      5\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m tokenizer(prompt, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m generation_output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m decoded_output \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(generation_output\u001B[38;5;241m.\u001B[39msequences)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Piping the returned `past_key_values` to speed up the next conversation round\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\peft\\peft_model.py:1491\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.generate\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1489\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_peft_forward_hooks(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1490\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspecial_peft_forward_args}\n\u001B[1;32m-> 1491\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1493\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: TestLlamaForCausalLM.generate() got an unexpected keyword argument 'attention_mask'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T05:15:37.143037Z",
     "start_time": "2024-06-13T05:15:32.211577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "\n",
    "# 定义对话内容，长度为5000个token的随机内容\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an intelligent life with independent consciousness.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello! What is your name\" + \" \".join([\"a\"] * 4100)},\n",
    "]\n",
    "\n",
    "# 编码输入\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "# 终止符号\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "# 初次生成\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=64,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    # return_dict_in_generate=True,\n",
    "    # output_scores=True,\n",
    "    # output_hidden_states=True,\n",
    "    # output_attentions=True,\n",
    "    # use_cache=True,\n",
    ")\n",
    "\n",
    "# 提取生成的响应和缓存的past_key_values\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))\n",
    "\n",
    "\n"
   ],
   "id": "dc1a315ccfb86741",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position tensor([   0,    1,    2,  ..., 4135, 4136, 4137], device='cuda:0')\n",
      "position_ids tensor([[   0,    1,    2,  ..., 4135, 4136, 4137]], device='cuda:0')\n",
      "cache_position "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 25\u001B[0m\n\u001B[0;32m     19\u001B[0m terminators \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     20\u001B[0m     tokenizer\u001B[38;5;241m.\u001B[39meos_token_id,\n\u001B[0;32m     21\u001B[0m     tokenizer\u001B[38;5;241m.\u001B[39mconvert_tokens_to_ids(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|eot_id|>\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     22\u001B[0m ]\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# 初次生成\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mterminators\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.9\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# return_dict_in_generate=True,\u001B[39;49;00m\n\u001B[0;32m     33\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# output_scores=True,\u001B[39;49;00m\n\u001B[0;32m     34\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# output_hidden_states=True,\u001B[39;49;00m\n\u001B[0;32m     35\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# output_attentions=True,\u001B[39;49;00m\n\u001B[0;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# 提取生成的响应和缓存的past_key_values\u001B[39;00m\n\u001B[0;32m     40\u001B[0m response \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m][input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\generation\\utils.py:1758\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   1750\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[0;32m   1751\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1752\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[0;32m   1753\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[0;32m   1754\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   1755\u001B[0m     )\n\u001B[0;32m   1757\u001B[0m     \u001B[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[1;32m-> 1758\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1759\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_warper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_warper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1762\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1764\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1766\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1767\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1769\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[0;32m   1770\u001B[0m     \u001B[38;5;66;03m# 11. prepare logits warper\u001B[39;00m\n\u001B[0;32m   1771\u001B[0m     prepared_logits_warper \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1772\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_logits_warper(generation_config) \u001B[38;5;28;01mif\u001B[39;00m generation_config\u001B[38;5;241m.\u001B[39mdo_sample \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1773\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\generation\\utils.py:2397\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001B[0m\n\u001B[0;32m   2394\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[0;32m   2396\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[1;32m-> 2397\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2398\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2399\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   2400\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2401\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2402\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[0;32m   2405\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\accelerate\\hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(module, *args, **kwargs)\u001B[0m\n\u001B[0;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:1164\u001B[0m, in \u001B[0;36mLlamaForCausalLM.forward\u001B[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[0;32m   1161\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m   1163\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[1;32m-> 1164\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1165\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1166\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1167\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1168\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1169\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1170\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1171\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1172\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1173\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1175\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpretraining_tp \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\accelerate\\hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(module, *args, **kwargs)\u001B[0m\n\u001B[0;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:968\u001B[0m, in \u001B[0;36mLlamaModel.forward\u001B[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[0;32m    957\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[0;32m    958\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[0;32m    959\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    965\u001B[0m         cache_position,\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    967\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 968\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    978\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\accelerate\\hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(module, *args, **kwargs)\u001B[0m\n\u001B[0;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:713\u001B[0m, in \u001B[0;36mLlamaDecoderLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001B[0m\n\u001B[0;32m    710\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm(hidden_states)\n\u001B[0;32m    712\u001B[0m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[1;32m--> 713\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    714\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    722\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[0;32m    724\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\accelerate\\hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(module, *args, **kwargs)\u001B[0m\n\u001B[0;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "Cell \u001B[1;32mIn[14], line 31\u001B[0m, in \u001B[0;36mTestLlamaAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     21\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     29\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor, Optional[torch\u001B[38;5;241m.\u001B[39mTensor], Optional[Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]]]:\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_position\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_position)\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mposition_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m, position_ids)\n\u001B[0;32m     34\u001B[0m     bsz, q_len, _ \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39msize()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\_tensor.py:464\u001B[0m, in \u001B[0;36mTensor.__repr__\u001B[1;34m(self, tensor_contents)\u001B[0m\n\u001B[0;32m    460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    461\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__repr__\u001B[39m, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, tensor_contents\u001B[38;5;241m=\u001B[39mtensor_contents\n\u001B[0;32m    462\u001B[0m     )\n\u001B[0;32m    463\u001B[0m \u001B[38;5;66;03m# All strings are unicode in Python 3.\u001B[39;00m\n\u001B[1;32m--> 464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tensor_str\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_str\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_contents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_contents\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\_tensor_str.py:697\u001B[0m, in \u001B[0;36m_str\u001B[1;34m(self, tensor_contents)\u001B[0m\n\u001B[0;32m    695\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(), torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39m_python_dispatch\u001B[38;5;241m.\u001B[39m_disable_current_modes():\n\u001B[0;32m    696\u001B[0m     guard \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_DisableFuncTorch()\n\u001B[1;32m--> 697\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_str_intern\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_contents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_contents\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\_tensor_str.py:617\u001B[0m, in \u001B[0;36m_str_intern\u001B[1;34m(inp, tensor_contents)\u001B[0m\n\u001B[0;32m    615\u001B[0m                     tensor_str \u001B[38;5;241m=\u001B[39m _tensor_str(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_dense(), indent)\n\u001B[0;32m    616\u001B[0m                 \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 617\u001B[0m                     tensor_str \u001B[38;5;241m=\u001B[39m \u001B[43m_tensor_str\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayout \u001B[38;5;241m!=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstrided:\n\u001B[0;32m    620\u001B[0m     suffixes\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayout=\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayout))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\_tensor_str.py:349\u001B[0m, in \u001B[0;36m_tensor_str\u001B[1;34m(self, indent)\u001B[0m\n\u001B[0;32m    345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _tensor_str_with_formatter(\n\u001B[0;32m    346\u001B[0m         \u001B[38;5;28mself\u001B[39m, indent, summarize, real_formatter, imag_formatter\n\u001B[0;32m    347\u001B[0m     )\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 349\u001B[0m     formatter \u001B[38;5;241m=\u001B[39m \u001B[43m_Formatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_summarized_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msummarize\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    350\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _tensor_str_with_formatter(\u001B[38;5;28mself\u001B[39m, indent, summarize, formatter)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\_tensor_str.py:133\u001B[0m, in \u001B[0;36m_Formatter.__init__\u001B[1;34m(self, tensor)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfloating_dtype:\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m tensor_view:\n\u001B[1;32m--> 133\u001B[0m         value_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    134\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_width, \u001B[38;5;28mlen\u001B[39m(value_str))\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\_tensor.py:990\u001B[0m, in \u001B[0;36mTensor.__format__\u001B[1;34m(self, format_spec)\u001B[0m\n\u001B[0;32m    988\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__format__\u001B[39m, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, format_spec)\n\u001B[0;32m    989\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_meta \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m Tensor:\n\u001B[1;32m--> 990\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__format__\u001B[39m(format_spec)\n\u001B[0;32m    991\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__format__\u001B[39m(\u001B[38;5;28mself\u001B[39m, format_spec)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:30:18.476099Z",
     "start_time": "2024-06-10T20:30:18.472128Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(past_key_values))",
   "id": "34090db3b8ce77e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:20:22.368495Z",
     "start_time": "2024-06-10T20:20:22.277495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用缓存进行后续生成\n",
    "# 定义对话内容\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you like?\"},\n",
    "]\n",
    "\n",
    "# 编码输入\n",
    "# new_input_ids = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     add_generation_prompt=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# ).to(model.device)\n",
    "\n",
    "new_input_ids = tokenizer(\"What do you like?\", return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "\n",
    "# 连接新输入和缓存\n",
    "new_outputs = model.generate(\n",
    "    new_input_ids, \n",
    "    max_new_tokens=64,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    use_cache=True,\n",
    "    past_key_values=past_key_values,\n",
    "    return_dict_in_generate=True,\n",
    ")\n",
    "\n",
    "new_response = new_outputs[0][new_input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(new_response, skip_special_tokens=True))"
   ],
   "id": "ce1200eb1cafc05b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "upper bound and larger bound inconsistent with step sign",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 19\u001B[0m\n\u001B[0;32m     15\u001B[0m new_input_ids \u001B[38;5;241m=\u001B[39m tokenizer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat do you like?\u001B[39m\u001B[38;5;124m\"\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39minput_ids\u001B[38;5;241m.\u001B[39mto(model\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# 连接新输入和缓存\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m new_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnew_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mterminators\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.6\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.9\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m new_response \u001B[38;5;241m=\u001B[39m new_outputs[\u001B[38;5;241m0\u001B[39m][new_input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:]\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(tokenizer\u001B[38;5;241m.\u001B[39mdecode(new_response, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\peft\\peft_model.py:1491\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.generate\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1489\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_peft_forward_hooks(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1490\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspecial_peft_forward_args}\n\u001B[1;32m-> 1491\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1493\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\generation\\utils.py:1758\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   1750\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[0;32m   1751\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1752\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[0;32m   1753\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[0;32m   1754\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   1755\u001B[0m     )\n\u001B[0;32m   1757\u001B[0m     \u001B[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[1;32m-> 1758\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1759\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_warper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_warper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1762\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1764\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1766\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1767\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1769\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[0;32m   1770\u001B[0m     \u001B[38;5;66;03m# 11. prepare logits warper\u001B[39;00m\n\u001B[0;32m   1771\u001B[0m     prepared_logits_warper \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1772\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_logits_warper(generation_config) \u001B[38;5;28;01mif\u001B[39;00m generation_config\u001B[38;5;241m.\u001B[39mdo_sample \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1773\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\generation\\utils.py:2390\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001B[0m\n\u001B[0;32m   2388\u001B[0m this_peer_finished \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   2389\u001B[0m unfinished_sequences \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(batch_size, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39minput_ids\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m-> 2390\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_initial_cache_position\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2392\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_unfinished_sequences(this_peer_finished, synced_gpus, device\u001B[38;5;241m=\u001B[39minput_ids\u001B[38;5;241m.\u001B[39mdevice):\n\u001B[0;32m   2393\u001B[0m     \u001B[38;5;66;03m# prepare model inputs\u001B[39;00m\n\u001B[0;32m   2394\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\memory\\Lib\\site-packages\\transformers\\generation\\utils.py:1326\u001B[0m, in \u001B[0;36mGenerationMixin._get_initial_cache_position\u001B[1;34m(self, input_ids, model_kwargs)\u001B[0m\n\u001B[0;32m   1324\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1325\u001B[0m     cur_len \u001B[38;5;241m=\u001B[39m input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m-> 1326\u001B[0m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_position\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpast_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcur_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_kwargs\n",
      "\u001B[1;31mRuntimeError\u001B[0m: upper bound and larger bound inconsistent with step sign"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from transformers import LlamaTokenizer",
   "id": "79b518e13663974f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
